<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Jacob Moss, PhD Student</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Raleway&display=swap" rel="stylesheet">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="images/favicon.ico">

</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
    <div class="row">
      <div class="one-half column">
        <h4 style="margin-top:20px">Jacob Daniel Moss</h4>
      </div>
      <div class="one-half column", style="text-align:center;margin-top:20px">
        <img alt="" width="60px" style="margin-right:8px;vertical-align: middle;" src="./images/cam_seal.webp">      
        <img alt="" width="60px" style="margin-left:8px;vertical-align: middle;" src="./images/darwin.gif">  
      </div>
    </div>


    <div class="row">

      <div class="one-half column" style="margin-top: 20px">
        <p>I'm a PhD student in Machine Learning at the University of Cambridge Computer Lab, 
        where I am supervised by Prof. Pietro Lió and Prof. Jeremy England. My research focuses on:</p>
        <ul>
          <li>Differential equation models of genetic regulation;</li>
          <li>Models of single-cell RNA, accessibility, and methylation;</li>
          <li>Latent Force Models;</li>
          <li>Stochastic Neural ODEs;</li>
          <li>Graph machine learning.</li>
        </ul>

        <p>
            I am also working on an <a href="./intro_probml.pdf">Introduction to Probabilistic Machine Learning booklet</a>, which is targeted
            at people with a background in computer science. It covers topics like MAP, Gaussian Processes, MCMC,
            Variational Inference, Stochastic Calculus, and more. It is updated regularly.
        </p>
        <p>
        Previously, I did a Master's in Advanced Computer Science at the University of 
        Cambridge. 
        Further to my academic experience, I have worked on a number of industry 
        projects, such as a non-invasive clinically certified heart rate 
        monitor wristband, which won Innovator of the Year at the 2018 Future Health 
        Summit, and an auction house asset-price prediction system for a 
        quantitative trading firm.
        </p>

        <p>
          Please feel free to contact me if you would like to collaborate on any of the research areas 
          listed above!
        </p>
        <ul>
          <li>Email: jm2311 at cam.ac.uk</li>
          <li>CV: <a href="./jacob-moss-cv.pdf">Curriculum Vitae</a></li>
        </ul>

      </div>
      <div class="one-half column" style="margin-top: 20px;text-align: center;">
        <img alt="" width="250px", style="margin-top:20px" src="./images/jacob.jpg">      
        <div>
          <a href="https://github.com/mossjacob"><img width="30px" src="images/github.svg"></a>
          <a href="https://www.linkedin.com/in/cobbles/"><img width="30px" src="images/linkedin.png"></a></div>
      </div>
    </div>

    <h4>Selected Publications</h4>
    
    <a href="https://arxiv.org/abs/2109.11851">
      <b>Approximate Latent Force Model Inference</b>
    </a>
    <p>
      Physically-inspired latent force models offer an interpretable alternative to purely data driven tools for inference in dynamical systems. They carry the structure of differential equations and the flexibility of Gaussian processes, yielding interpretable parameters and dynamics-imposed latent functions. However, the existing inference techniques associated with these models rely on the exact computation of posterior kernel terms which are seldom available in analytical form. Most applications relevant to practitioners, such as Hill equations or diffusion equations, are hence intractable. In this paper, we overcome these computational problems by constructing a variational solution to a general class of non-linear and parabolic partial differential equation latent force models. Further, we show that a neural operator approach can scale our model to thousands of instances, enabling fast, distributed computation.
    </p>
    <b>Moss, J. D.</b>, Opolka, F. L., Dumitrascu, D., Liò, P.<br>
    <em>In Science-Guided AI Symposium at AAAI 2021.</em><br>
    <em>Also in NeurIPS 2021 workshop on Machine Learning Learning and the Physical Sciences.</em><br>
    <b><a href="https://arxiv.org/abs/2104.14290">Paper</a> </b>
    
    <br>
    <hr>
    <a href="https://arxiv.org/abs/2104.14290">
      <b>Meta-learning using privileged information for dynamics</b>
    </a>
    <p>
      In the physical sciences, we often have access to structured knowledge in addition to raw observations of a system, such as the value of a conserved quantity or a description of an understood component. Taking advantage of the aggregation flexibility, we extend the Neural ODE Process model to use additional information within the Learning Using Privileged Information setting, and we validate our extension with experiments showing improved accuracy and calibration on simulated dynamics tasks.
    </p>
    Day, B., Norcliffe, A., <b>Moss, J. D.</b>, & Liò, P.<br>
    <em>In ICLR 2021 workshops on Learning to Learn and SimDL.</em><br>
    <b><a href="https://arxiv.org/abs/2104.14290">Paper</a> </b>
    
    <br>
    <hr>
    <a href="https://openreview.net/forum?id=27acGyyI1BY">
      <b>Neural ODE Processes</b>
    </a>
    <p>
      We introduce Neural ODE Processes (NDPs), a new class of stochastic processes determined by a distribution over Neural ODEs. By maintaining an adaptive data-dependent distribution over the underlying ODE, we show that our model can successfully capture the dynamics of low-dimensional systems from just a few data-points. At the same time, we demonstrate that NDPs scale up to challenging high-dimensional time-series with unknown latent dynamics such as rotating MNIST digits.
    </p>
    Norcliffe, A., Bodnar, C., Day, B., <b>Moss, J. D.</b>, & Liò, P.<br>
    <em>In International Conference on Learning Representations. ICLR, 2021</em><br>
    <em>Also published as a <a href="https://ml4physicalsciences.github.io/2020/files/NeurIPS_ML4PS_2020_66.pdf">workshop paper</a> at NeurIPS workshop on Machine Learning and the Physical Sciences. NeurIPS, 2020</em><br>
    <b><a href="https://openreview.net/forum?id=27acGyyI1BY">Paper</a> | <a href="https://github.com/crisbodnar/ndp">Code</a></b>

    <br>
    <hr>

    <b><a href="https://arxiv.org/abs/2010.02555">Gene Regulatory Network Inference with Latent Force Models</a></b>
    <p>
    </p>
    <p>
      <b>Moss, J. D.</b>, and Liò, P. . Arxiv, 2020.
    </p>
    

    <h4>Talks</h4>
    <p>
      <ul>
        <li>Feb 2021: <a href="http://talks.cam.ac.uk/talk/index/155344">AI Research Group Talks: Neural ODE Processes</a></li>
        <li>Nov 2020: AI Research Group Crit Session: Wishart Processes</a></li>
      </ul>
    </p>
    <h4>Teaching & Supervising</h4>
    <p>
      <ul>
        <li>Machine Learning with Real World Data (2021)</li>
      </ul>
    </p>

  </div>

<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
